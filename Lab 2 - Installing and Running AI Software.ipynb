{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/01-nvidia-logo-horiz-500x200-2c50-d@2x.png\" alt=\"NVIDIA Logo\" style=\"width: 300px; height: auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Installing and Running AI Software\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "### Audience\n",
    "The workbook is intended for technical training students.\n",
    "\n",
    "### Objectives\n",
    "In this practice, you will:\n",
    "\n",
    "    ✓ Install the NVIDIA Container Toolkit on a server\n",
    "    ✓ Run a container from NGC to train and recognize handwritten numbers\n",
    "\n",
    "### Prerequisites and Guidelines\n",
    "There are no prerequisites for this lab.\n",
    "\n",
    "### Notice\n",
    "Please follow the instructions below carefully to successfully complete the practice.\n",
    "If you encounter technical issues, please contact the NVIDIA Networking Academy team:\n",
    "nbu-academy-support@nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise, you will install the NVIDIA Container Toolkit and check if the toolkit is installed and working properly by running a container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Configure a production repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \\\n",
    "    | sudo gpg --dearmor --yes -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \\\n",
    "    | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \\\n",
    "    | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Update the packages list from the repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nvidia-driver-local-repo-ubuntu2404-580.105.08  InRelease [1572 B]\n",
      "Hit:2 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:1 file:/var/nvidia-driver-local-repo-ubuntu2404-580.105.08  InRelease [1572 B]\n",
      "Hit:3 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-updates InRelease    \n",
      "Hit:4 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-backports InRelease  \n",
      "Hit:5 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease \n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:7 https://download.docker.com/linux/ubuntu jammy InRelease                 \n",
      "Hit:8 https://apt.grafana.com stable InRelease                                 \n",
      "Hit:9 https://repos.influxdata.com/debian stable InRelease                     \n",
      "Hit:10 https://cli.github.com/packages stable InRelease                        \n",
      "Hit:11 http://security.ubuntu.com/ubuntu jammy-security InRelease              \n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Install the NVIDIA Container Toolkit packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "nvidia-container-toolkit is already the newest version (1.18.0-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y nvidia-container-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Configure a container runtime to enable support for NVIDIA GPUs via the NVIDIA Container Toolkit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0000] Loading config from /etc/docker/daemon.json  \n",
      "\u001b[36mINFO\u001b[0m[0000] Wrote updated config to /etc/docker/daemon.json \n",
      "\u001b[36mINFO\u001b[0m[0000] It is recommended that docker daemon be restarted. \n"
     ]
    }
   ],
   "source": [
    "!sudo nvidia-ctk runtime configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 - Restart the Docker service:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo systemctl restart docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Run the NVIDIA Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Run a container and check if the NVIDIA Container Toolkit operates as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 17:01:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   46C    P8             17W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your output should render the NVIDIA-SMI table without error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Questions:\n",
    "\n",
    "    ✓ What command is executed in the container?\n",
    "    ✓ What is the driver version in your output?\n",
    "    ✓ What is the CUDA version in your output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 2: Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise you will use a Docker container with an NVIDIA GPU to build a simple neural network to recognize a numeral digit from an image file.\n",
    "\n",
    "This exercise assumes that the previous exercise \"Install Container Toolkit\" was completed successfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install and Run PyTorch Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Run the following command to install a container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.01-py3: Pulling from nvidia/pytorch\n",
      "Digest: sha256:96990c82825613c3bdeebb66675c7c91b0123f64a5895623316dc5b824e0d7a9\n",
      "Status: Image is up to date for nvcr.io/nvidia/pytorch:25.01-py3\n",
      "nvcr.io/nvidia/pytorch:25.01-py3\n"
     ]
    }
   ],
   "source": [
    "!sudo docker pull nvcr.io/nvidia/pytorch:25.01-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Prepare Program Code Files for Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will train a model to recognize a numeral in a 24x24 pixel image.\n",
    "\n",
    "Navigate to the `~/notebooks/module8` directory, which contains the following files:\n",
    "\n",
    "    ✓ train.py – Program that trains the AI\n",
    "    ✓ test.py – Program that uses the trained AI\n",
    "    ✓ 2.png, 7.png and 8.png – Image files used to test the AI\n",
    "\n",
    "You can create a few 24x24 pixel images using software like MS Paint, writing a number in each image, or using files downloaded from GitHub. In our example, these are the images we used with significant magnification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.png  7.png  8.png  data  mnist_cnn.pt  test.py  timer.py  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls ~/notebooks/module8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Train the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Before you start training your model, run nvidia-smi and make sure to remember or write down the following information:\n",
    "\n",
    "    ✓ The GPU's memory usage before training begins\n",
    "    ✓ The current GPU utilization\n",
    "    ✓ The list of processes currently running on the GPU\n",
    "\n",
    "Retain these details for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 17:01:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   46C    P0             19W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Run the training using the command \"python train.py\". During the training, several epochs will run:\n",
    "\n",
    "**Note:** This command will start the training script in the container we generated. It should output each epoch with the relevant stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "Training for 1 epochs on cuda\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312044\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.117028\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.067098\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.149368\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.022770\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.122479\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.038422\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.023687\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.096688\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.003127\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 9831/10000 (98%)\n",
      "\n",
      "Device : cuda\n",
      "Time : 16.14 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u train.py 1 | tee /tmp/gpu_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - While your model is training, run the nvidia-smi command in a terminal in a new tab.\n",
    "\n",
    "To open a new terminal, click the **+** button in JupyterLab and select **Terminal** from the Launcher:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"attachment:cfac182f-6cfc-4b44-8067-55acd60ca44e.png\" style=\"width: 50%\">\n",
    "</div>\n",
    "\n",
    "Compare the current output to what you observed before starting the training. Take note of the following:\n",
    "\n",
    "    ✓ What was the GPU memory usage during training, compared to before you started?\n",
    "    ✓ How did GPU utilization change during training?\n",
    "    ✓ Which processes were running on the GPU during training?\n",
    "    ✓ How much time did the model training take to complete?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a simple helper script called `timer` that will compare GPU vs CPU performance at the end of this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try the Trained Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Use the test.py file to check if the trained model can recognize the numerals from the image files. \n",
    "\n",
    "By default, test.py will attempt to recognize the numeral in the file 7.png. To test a different file, provide its name as a parameter.\n",
    "\n",
    "**Note:** These commands should be run from within the Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "Processing file: 7.png\n",
      "The predicted number is: 7\n",
      "Device : cuda\n",
      "Time : 0.54 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py | tee /tmp/gpu_7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Test with a different image file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "Processing file: 8.png\n",
      "The predicted number is: 8\n",
      "Device : cuda\n",
      "Time : 0.55 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py 8.png | tee /tmp/gpu_8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Compare the Load on GPU vs CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 - Test Inference using CPU rather than GPU\n",
    "\n",
    "**Note:** The `--gpus all` flag has been removed. The container will now run CPU-only, without utilizing the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "ERROR: The NVIDIA Driver is present, but CUDA failed to initialize.  GPU functionality will not be available.\n",
      "   [[ No CUDA-capable device is detected (error 100) ]]\n",
      "\n",
      "Processing file: 7.png\n",
      "The predicted number is: 7\n",
      "Device : cpu\n",
      "Time : 0.04 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --ipc=host --rm -e CUDA_VISIBLE_DEVICES= -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py | tee /tmp/cpu_7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - The previously used files should still be in the container. Start training the model again.\n",
    "\n",
    "**Question:** How much time did the model training take compared to GPU training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "ERROR: The NVIDIA Driver is present, but CUDA failed to initialize.  GPU functionality will not be available.\n",
      "   [[ No CUDA-capable device is detected (error 100) ]]\n",
      "\n",
      "Training for 1 epochs on cpu\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307606\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.075259\n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --ipc=host --rm -e CUDA_VISIBLE_DEVICES= -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u train.py 1 | tee /tmp/cpu_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/01-nvidia-logo-horiz-500x200-2c50-d@2x.png\" alt=\"NVIDIA Logo\" style=\"width: 300px; height: auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Installing and Running AI Software\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "### Audience\n",
    "The workbook is intended for technical training students.\n",
    "\n",
    "### Objectives\n",
    "In this practice, you will:\n",
    "\n",
    "    ✓ Install the NVIDIA Container Toolkit on a server\n",
    "    ✓ Run a container from NGC to train and recognize handwritten numbers\n",
    "\n",
    "### Prerequisites and Guidelines\n",
    "There are no prerequisites for this lab.\n",
    "\n",
    "### Notice\n",
    "Please follow the instructions below carefully to successfully complete the practice.\n",
    "If you encounter technical issues, please contact the NVIDIA Networking Academy team:\n",
    "nbu-academy-support@nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise, you will install the NVIDIA Container Toolkit and check if the toolkit is installed and working properly by running a container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Configure a production repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor --yes -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Update the packages list from the repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Install the NVIDIA Container Toolkit packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install -y nvidia-container-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Configure a container runtime to enable support for NVIDIA GPUs via the NVIDIA Container Toolkit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo nvidia-ctk runtime configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 - Restart the Docker service:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo systemctl restart docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Run the NVIDIA Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Run a container and check if the NVIDIA Container Toolkit operates as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 16:24:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   45C    P0             20W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your output should render the NVIDIA-SMI table without error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Questions:\n",
    "\n",
    "    ✓ What command is executed in the container?\n",
    "    ✓ What is the driver version in your output?\n",
    "    ✓ What is the CUDA version in your output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 2: Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise you will use a Docker container with an NVIDIA GPU to build a simple neural network to recognize a numeral digit from an image file.\n",
    "\n",
    "This exercise assumes that the previous exercise \"Install Container Toolkit\" was completed successfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install and Run PyTorch Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Run the following command to install a container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.01-py3: Pulling from nvidia/pytorch\n",
      "Digest: sha256:96990c82825613c3bdeebb66675c7c91b0123f64a5895623316dc5b824e0d7a9\n",
      "Status: Image is up to date for nvcr.io/nvidia/pytorch:25.01-py3\n",
      "nvcr.io/nvidia/pytorch:25.01-py3\n"
     ]
    }
   ],
   "source": [
    "!sudo docker pull nvcr.io/nvidia/pytorch:25.01-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Create a working folder for the project:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p docker_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Before running the container, you may want to use \"tmux\" or \"screen\" to run monitoring commands on the host. Alternatively, you can open a new SSH connection to the host.\n",
    "\n",
    "Run the container using the following command:\n",
    "\n",
    "```bash\n",
    "sudo docker run --gpus all --ipc=host -it --rm -v /home/ubuntu/module8/materials:/workspace nvcr.io/nvidia/pytorch:25.01-py3\n",
    "```\n",
    "\n",
    "**Note:** The directory `/home/ubuntu/module8` on the host is mapped to the \"workspace\" directory in the container. This means that any file created in this directory on the host will appear in the container, and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Prepare Program Code Files for Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will train a model to recognize a numeral in a 24x24 pixel image.\n",
    "\n",
    "Navigate to the `~/notebooks/module8` directory, which contains the following files:\n",
    "\n",
    "    ✓ train.py – Program that trains the AI\n",
    "    \n",
    "    ✓ test.py – Program that uses the trained AI\n",
    "    \n",
    "    ✓ 2.png, 7.png and 8.png – Image files used to test the AI\n",
    "\n",
    "You can create a few 24x24 pixel images using software like MS Paint, writing a number in each image, or using files downloaded from GitHub. In our example, these are the images we used with significant magnification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.png  7.png  8.png  data  mnist_cnn.pt  test.py  timer.py  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls ~/notebooks/module8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Train the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Before you start training your model, run nvidia-smi and make sure to remember or write down the following information:\n",
    "\n",
    "    ✓ The GPU's memory usage before training begins\n",
    "    \n",
    "    ✓ The current GPU utilization\n",
    "    \n",
    "    ✓ The list of processes currently running on the GPU\n",
    "\n",
    "Retain these details for later reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 16:25:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   45C    P8             22W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Run the training using the command \"python train.py\". During the training, several epochs will run:\n",
    "\n",
    "**Note:** This command should be run from within the Docker container. You may need to execute the docker run command from Task 1.3 first.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "Train Epoch: 1 [0/60000 (0%)]   Loss: 2.303346             \n",
    "Train Epoch: 1 [6400/60000 (11%)]       Loss: 0.147270     \n",
    "Train Epoch: 1 [12800/60000 (21%)]      Loss: 0.200906     \n",
    "Train Epoch: 1 [19200/60000 (32%)]      Loss: 0.102331     \n",
    "Train Epoch: 1 [25600/60000 (43%)]      Loss: 0.226644     \n",
    "Train Epoch: 1 [32000/60000 (53%)]      Loss: 0.024340     \n",
    "Train Epoch: 1 [38400/60000 (64%)]      Loss: 0.034060     \n",
    "Train Epoch: 1 [44800/60000 (75%)]      Loss: 0.005021     \n",
    "Train Epoch: 1 [51200/60000 (85%)]      Loss: 0.002311     \n",
    "Train Epoch: 1 [57600/60000 (96%)]      Loss: 0.022788     \n",
    "                                                           \n",
    "Test set: Average loss: 0.0406, Accuracy: 9878/10000 (99%)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 112MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 23.9MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 69.2MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 17.4MB/s]\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.286770\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.172383\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.239802\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.159930\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.015634\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.073613\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.044037\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.126591\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.052233\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.008262\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.085948\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.095333\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.042386\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.100825\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.026074\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.074957\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.043299\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.048519\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.002052\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.003035\n",
      "\n",
      "Test set: Average loss: 0.0396, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.008537\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.000556\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000379\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.006105\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.050191\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.003547\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.023059\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.048431\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.002799\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.028401\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000237\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.011436\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000726\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000424\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000108\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.013152\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000155\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011671\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.002593\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.012848\n",
      "\n",
      "Test set: Average loss: 0.0423, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000476\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000036\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001221\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000005\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.026085\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.040403\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.004184\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.072581\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000842\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.187649\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Device : cuda\n",
      "Time : 78.09 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u train.py | tee /tmp/gpu_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - While your model is training, run the nvidia-smi command again.\n",
    "\n",
    "Compare the current output to what you observed before starting the training. Take note of the following:\n",
    "\n",
    "    ✓ What was the GPU memory usage during training, compared to before you started?\n",
    "    ✓ How did GPU utilization change during training?\n",
    "    ✓ Which processes were running on the GPU during training?\n",
    "    ✓ How much time did the model training take to complete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 16:27:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   51C    P0             19W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a simple helper script called `timer` that will compare GPU vs CPU performance at the end of this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try the Trained Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Use the test.py file to check if the trained model can recognize the numerals from the image files. \n",
    "\n",
    "By default, test.py will attempt to recognize the numeral in the file 7.png. To test a different file, provide its name as a parameter.\n",
    "\n",
    "**Note:** These commands should be run from within the Docker container.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```bash\n",
    "root@20a0e58202b3:/workspace/AIDC-Professional# python test.py \n",
    "Processing file: 7.png\n",
    "The predicted number is: 7\n",
    "Device : cuda\n",
    "Time : 3.02 seconds \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "Processing file: 7.png\n",
      "The predicted number is: 7\n",
      "Device : cuda\n",
      "Time : 0.55 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py | tee /tmp/gpu_7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Test with a different image file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "Processing file: 8.png\n",
      "The predicted number is: 8\n",
      "Device : cuda\n",
      "Time : 0.55 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --gpus all --ipc=host --rm -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py 8.png | tee /tmp/gpu_8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Compare the Load on GPU vs CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 - Use the command 'exit' to exit the running container.\n",
    "\n",
    "Restart the container, but this time use the command:\n",
    "\n",
    "```bash\n",
    "sudo docker run --ipc=host -it --rm -v /home/ubuntu/module8/materials:/workspace nvcr.io/nvidia/pytorch:25.01-py3\n",
    "```\n",
    "\n",
    "**Note:** The `--gpus all` flag has been removed. The container will now run CPU-only, without utilizing the GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "ERROR: The NVIDIA Driver is present, but CUDA failed to initialize.  GPU functionality will not be available.\n",
      "   [[ No CUDA-capable device is detected (error 100) ]]\n",
      "\n",
      "Processing file: 7.png\n",
      "The predicted number is: 7\n",
      "Device : cpu\n",
      "Time : 0.04 seconds \n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --ipc=host --rm -e CUDA_VISIBLE_DEVICES= -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u test.py | tee /tmp/cpu_7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - The previously used files should still be in the container. Start training the model again.\n",
    "\n",
    "**Question:** How much time did the model training take compared to GPU training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "== PyTorch ==\n",
      "=============\n",
      "\n",
      "NVIDIA Release 25.01 (build 134983853)\n",
      "PyTorch Version 2.6.0a0+ecf3bae\n",
      "Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "Copyright (c) 2014-2024 Facebook Inc.\n",
      "Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n",
      "Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n",
      "Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n",
      "Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n",
      "Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n",
      "Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n",
      "Copyright (c) 2015      Google Inc.\n",
      "Copyright (c) 2015      Yangqing Jia\n",
      "Copyright (c) 2013-2016 The Caffe contributors\n",
      "All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "ERROR: The NVIDIA Driver is present, but CUDA failed to initialize.  GPU functionality will not be available.\n",
      "   [[ No CUDA-capable device is detected (error 100) ]]\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297871\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.430037\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.028770\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.009052\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.019325\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.077170\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.043497\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.049235\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.003602\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.006465\n",
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 9885/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.009864\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.098465\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.045505\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.008762\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.027923\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.026404\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.000683\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.004051\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.023218\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.002097\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9885/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.016774\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.003124\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.032883\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.137758\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.017493\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002328\n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --ipc=host --rm -e CUDA_VISIBLE_DEVICES= -v /home/ubuntu/module8/materials:/workspace -w /workspace nvcr.io/nvidia/pytorch:25.01-py3 python -u train.py | tee /tmp/cpu_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

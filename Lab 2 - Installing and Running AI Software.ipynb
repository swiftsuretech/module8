{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/01-nvidia-logo-horiz-500x200-2c50-d@2x.png\" alt=\"NVIDIA Logo\" style=\"width: 300px; height: auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Installing and Running AI Software\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "### Audience\n",
    "The workbook is intended for technical training students.\n",
    "\n",
    "### Objectives\n",
    "In this practice, you will:\n",
    "\n",
    "    ✓ Install the NVIDIA Container Toolkit on a server\n",
    "    \n",
    "    ✓ Run a container from NGC to train and recognize handwritten numbers\n",
    "\n",
    "### Prerequisites and Guidelines\n",
    "There are no prerequisites for this lab.\n",
    "\n",
    "### Notice\n",
    "Please follow the instructions below carefully to successfully complete the practice.\n",
    "If you encounter technical issues, please contact the NVIDIA Networking Academy team:\n",
    "nbu-academy-support@nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise, you will install the NVIDIA Container Toolkit and check if the toolkit is installed and working properly by running a container.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install the Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Configure a production repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor --yes -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Update the packages list from the repository:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nvidia-driver-local-repo-ubuntu2404-580.105.08  InRelease [1572 B]\n",
      "Get:1 file:/var/nvidia-driver-local-repo-ubuntu2404-580.105.08  InRelease [1572 B]\n",
      "Hit:2 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy InRelease            \n",
      "Get:3 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:4 https://download.docker.com/linux/ubuntu jammy InRelease                 \n",
      "Hit:5 https://repos.influxdata.com/debian stable InRelease                     \n",
      "Hit:6 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease \n",
      "Get:7 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:9 https://apt.grafana.com stable InRelease                                 \n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:11 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3089 kB]\n",
      "Get:12 http://us-east4.gce.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1242 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2824 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main Translation-en [409 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4726 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted Translation-en [884 kB]\n",
      "Fetched 13.6 MB in 3s (4859 kB/s)                                \n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Install the NVIDIA Container Toolkit packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "nvidia-container-toolkit is already the newest version (1.18.0-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y nvidia-container-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 - Configure a container runtime to enable support for NVIDIA GPUs via the NVIDIA Container Toolkit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0000] Loading config from /etc/docker/daemon.json  \n",
      "\u001b[36mINFO\u001b[0m[0000] Wrote updated config to /etc/docker/daemon.json \n",
      "\u001b[36mINFO\u001b[0m[0000] It is recommended that docker daemon be restarted. \n"
     ]
    }
   ],
   "source": [
    "!sudo nvidia-ctk runtime configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 - Restart the Docker service:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo systemctl restart docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Run the NVIDIA Container Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Run a container and check if the NVIDIA Container Toolkit operates as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 18:36:21 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   38C    P0             16W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does your output resemble the output as seen below?\n",
    "\n",
    "```\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA H100 NVL                Off |   00000000:B5:00.0 Off |                    0 |\n",
    "| N/A   51C    P0            124W /  400W |       1MiB /  95830MiB |      0%      Default |\n",
    "|                                         |                        |             Disabled |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "                                                                                         \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|  No running processes found                                                             |\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 Questions:\n",
    "\n",
    "    ✓ What command is executed in the container?\n",
    "    \n",
    "    ✓ What is the driver version in your output?\n",
    "    \n",
    "    ✓ What is the CUDA version in your output?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 2: Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice objectives:\n",
    "\n",
    "In this exercise you will use a Docker container with an NVIDIA GPU to build a simple neural network to recognize a numeral digit from an image file.\n",
    "\n",
    "This exercise assumes that the previous exercise \"Install Container Toolkit\" was completed successfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Install and Run PyTorch Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Run the following command to install a container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.01-py3: Pulling from nvidia/pytorch\n",
      "\n",
      "\u001b[1Bb265507a: Pulling fs layer \n",
      "\u001b[1Bdd940fc6: Pulling fs layer \n",
      "\u001b[1Bb7e55b61: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1Bff093155: Pulling fs layer \n",
      "\u001b[1Bfd5dddb1: Pulling fs layer \n",
      "\u001b[1B63dd6b7e: Pulling fs layer \n",
      "\u001b[1B4f040cbe: Pulling fs layer \n",
      "\u001b[1B8ea39070: Pulling fs layer \n",
      "\u001b[1B4e451322: Pulling fs layer \n",
      "\u001b[1B80752b35: Pulling fs layer \n",
      "\u001b[1B16b4865e: Pulling fs layer \n",
      "\u001b[1B3b71b07b: Pulling fs layer \n",
      "\u001b[1B59b21c0f: Pulling fs layer \n",
      "\u001b[1B12f82f03: Pulling fs layer \n",
      "\u001b[1B45aa1d7e: Pulling fs layer \n",
      "\u001b[1B04ab24c5: Pulling fs layer \n",
      "\u001b[1Ba2f2d5bd: Pulling fs layer \n",
      "\u001b[1B8363f368: Pulling fs layer \n",
      "\u001b[1B7f42fa23: Pulling fs layer \n",
      "\u001b[1B6e8d8318: Pulling fs layer \n",
      "\u001b[1B3134baa1: Pulling fs layer \n",
      "\u001b[1B77b797d2: Pulling fs layer \n",
      "\u001b[1Babeffa5b: Pulling fs layer \n",
      "\u001b[1B024db52a: Pulling fs layer \n",
      "\u001b[1Bd4d2d207: Pulling fs layer \n",
      "\u001b[24B700ef54: Pulling fs layer \n",
      "\u001b[1B6c1997d4: Pulling fs layer \n",
      "\u001b[1B09fcf888: Pulling fs layer \n",
      "\u001b[1B6d21c391: Pulling fs layer \n",
      "\u001b[1B583d0756: Pulling fs layer \n",
      "\u001b[1B65c05817: Pulling fs layer \n",
      "\u001b[1B3986b8df: Pulling fs layer \n",
      "\u001b[1B6aef40fb: Pulling fs layer \n",
      "\u001b[1Bfc731425: Pulling fs layer \n",
      "\u001b[1B067270f9: Pulling fs layer \n",
      "\u001b[34B700ef54: Pulling fs layer \n",
      "\u001b[1Bdbc970be: Pulling fs layer \n",
      "\u001b[1B6a22ad93: Pulling fs layer \n",
      "\u001b[1B7e3f78ba: Pulling fs layer \n",
      "\u001b[1B6439cf64: Pulling fs layer \n",
      "\u001b[1B1553aeb1: Pulling fs layer \n",
      "\u001b[1B8769314d: Pulling fs layer \n",
      "\u001b[1B2a8a00b2: Pulling fs layer \n",
      "\u001b[1B23c296bb: Pulling fs layer \n",
      "\u001b[1B04527ac4: Pulling fs layer \n",
      "\u001b[1Ba953a32b: Pulling fs layer \n",
      "\u001b[1B051b387d: Pulling fs layer \n",
      "\u001b[46B700ef54: Pulling fs layer \n",
      "\u001b[1B3ccfa190: Pulling fs layer \n",
      "\u001b[1Bf8b01956: Pulling fs layer \n",
      "\u001b[49B700ef54: Pulling fs layer \n",
      "\u001b[1B5861492a: Pulling fs layer \n",
      "\u001b[1B808cfc0a: Pulling fs layer \n",
      "\u001b[18BDigest: sha256:96990c82825613c3bdeebb66675c7c91b0123f64a5895623316dc5b824e0d7a9\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/pytorch:25.01-py3\n",
      "nvcr.io/nvidia/pytorch:25.01-py3\n"
     ]
    }
   ],
   "source": [
    "!sudo docker pull nvcr.io/nvidia/pytorch:25.01-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Create a working folder for the project:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p docker_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Before running the container, you may want to use \"tmux\" or \"screen\" to run monitoring commands on the host. Alternatively, you can open a new SSH connection to the host.\n",
    "\n",
    "Run the container using the following command:\n",
    "\n",
    "```bash\n",
    "sudo docker run --gpus all --ipc=host -it --rm -v /home/student/AI_Infra/module8:/workspace nvcr.io/nvidia/pytorch:25.01-py3\n",
    "```\n",
    "\n",
    "**Note:** The directory `/home/student/AI_Infra/module8` on the host is mapped to the \"workspace\" directory in the container. This means that any file created in this directory on the host will appear in the container, and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Prepare Program Code Files for Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will train a model to recognize a numeral in a 24x24 pixel image.\n",
    "\n",
    "Navigate to the `~/AI_Infra/module8` directory, which contains the following files:\n",
    "\n",
    "    ✓ train.py – Program that trains the AI\n",
    "    \n",
    "    ✓ test.py – Program that uses the trained AI\n",
    "    \n",
    "    ✓ 2.png, 7.png and 8.png – Image files used to test the AI\n",
    "\n",
    "You can create a few 24x24 pixel images using software like MS Paint, writing a number in each image, or using files downloaded from GitHub. In our example, these are the images we used with significant magnification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/AI_Infra/module8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Train the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - Before you start training your model, run nvidia-smi and make sure to remember or write down the following information:\n",
    "\n",
    "    ✓ The GPU's memory usage before training begins\n",
    "    \n",
    "    ✓ The current GPU utilization\n",
    "    \n",
    "    ✓ The list of processes currently running on the GPU\n",
    "\n",
    "Retain these details for later reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Run the training using the command \"python train.py\". During the training, several epochs will run:\n",
    "\n",
    "**Note:** This command should be run from within the Docker container. You may need to execute the docker run command from Task 1.3 first.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "Train Epoch: 1 [0/60000 (0%)]   Loss: 2.303346             \n",
    "Train Epoch: 1 [6400/60000 (11%)]       Loss: 0.147270     \n",
    "Train Epoch: 1 [12800/60000 (21%)]      Loss: 0.200906     \n",
    "Train Epoch: 1 [19200/60000 (32%)]      Loss: 0.102331     \n",
    "Train Epoch: 1 [25600/60000 (43%)]      Loss: 0.226644     \n",
    "Train Epoch: 1 [32000/60000 (53%)]      Loss: 0.024340     \n",
    "Train Epoch: 1 [38400/60000 (64%)]      Loss: 0.034060     \n",
    "Train Epoch: 1 [44800/60000 (75%)]      Loss: 0.005021     \n",
    "Train Epoch: 1 [51200/60000 (85%)]      Loss: 0.002311     \n",
    "Train Epoch: 1 [57600/60000 (96%)]      Loss: 0.022788     \n",
    "                                                           \n",
    "Test set: Average loss: 0.0406, Accuracy: 9878/10000 (99%)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - While your model is training, run the nvidia-smi command again.\n",
    "\n",
    "Compare the current output to what you observed before starting the training. Take note of the following:\n",
    "\n",
    "    ✓ What was the GPU memory usage during training, compared to before you started?\n",
    "    \n",
    "    ✓ How did GPU utilization change during training?\n",
    "    \n",
    "    ✓ Which processes were running on the GPU during training?\n",
    "    \n",
    "    ✓ How much time did the model training take to complete?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try the Trained Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Use the test.py file to check if the trained model can recognize the numerals from the image files. \n",
    "\n",
    "By default, test.py will attempt to recognize the numeral in the file 7.png. To test a different file, provide its name as a parameter.\n",
    "\n",
    "**Note:** These commands should be run from within the Docker container.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```bash\n",
    "root@20a0e58202b3:/workspace/AIDC-Professional# python test.py \n",
    "Processing file: 7.png\n",
    "The predicted number is: 7\n",
    "Device : cuda\n",
    "Time : 3.02 seconds \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Test with a different image file:\n",
    "\n",
    "```bash\n",
    "root@20a0e58202b3:/workspace/AIDC-Professional# python test.py 8.png\n",
    "Processing file: 8.png\n",
    "The predicted number is: 7\n",
    "Device : cuda\n",
    "Time : 3.02 seconds\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Compare the Load on GPU vs CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 - Use the command 'exit' to exit the running container.\n",
    "\n",
    "Restart the container, but this time use the command:\n",
    "\n",
    "```bash\n",
    "sudo docker run --ipc=host -it --rm -v /home/student/AI_Infra/module8:/workspace nvcr.io/nvidia/pytorch:25.01-py3\n",
    "```\n",
    "\n",
    "**Note:** The `--gpus all` flag has been removed. The container will now run CPU-only, without utilizing the GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - The previously used files should still be in the container. Start training the model again.\n",
    "\n",
    "**Question:** How much time did the model training take compared to GPU training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
